<html><head><title>Параллельная обработка данных - лекция 5. Message Passing Interface (MPI)</title>



<link href="mpi_files/default.css" rel="stylesheet" type="text/css"></head><body onload="if (parent.index!=null) parent.index.SwitchOn(7);" bgcolor="#f0ffff">
<table border="0" cellpadding="3" cellspacing="0" width="100%"><tbody><tr bgcolor="#800000">
<td bgcolor="#008080"><font color="#ffffff"><b>&nbsp;ИНФОРМАЦИЯ&nbsp;</b></font>
</td><td align="right" bgcolor="#008080"><a href="http://parallel.ru/parallel/" target="_top"><img src="mpi_files/pc4.gif" border="0"><img src="mpi_files/pcHome.gif" border="0"></a>
</td></tr></tbody></table>
<p class="copyright">© <em>Воеводин Вл.В.</em><br>
<a href="http://parallel.ru/vvv/index.html">Курс лекций</a><br>"Параллельная обработка данных"

</p><h1>Лекция 5. Технологии параллельного программирования.<br> Message Passing Interface (MPI)</h1>
<p>План лекции:
</p><ul>
<li><a href="#p1">MPI. Терминология и обозначения</a>
</li><li><a href="#p2">Общие процедуры MPI</a>
</li><li><a href="#p3">Прием/передача сообщений между отдельными процессами</a>
</li><li><a href="#p4">Объединение запросов на взаимодействие</a>
</li><li><a href="#p5">Совмещенные прием/передача сообщений</a>
</li><li><a href="#p6">Коллективные взаимодействия процессов</a>
</li><li><a href="#p7">Синхронизация процессов</a>
</li><li><a href="#p8">Работа с группами процессов</a>
</li><li><a href="#p9">Предопределенные константы</a>
</li><li><a href="http://parallel.ru/vvv/examples.html">Примеры MPI-программ</a>
</li></ul>
<hr>

<a name="p1"></a>
<h3>MPI. Терминология и обозначения</h3>

<p><em>MPI - message passing interface</em> - библиотека функций, предназначенная
для поддержки работы параллельных процессов в терминах передачи сообщений.

</p><p><em>Номер процесса</em> - целое неотрицательное число,
являющееся уникальным
атрибутом каждого процесса. 

</p><p><em>Атрибуты сообщения</em> - номер процесса-отправителя, номер процесса-получателя
и идентификатор сообщения. Для них заведена структура <em>MPI_Status</em>,
содержащая три поля: <em>MPI_Source</em> (номер процесса отправителя), <em>MPI_Tag</em>
(идентификатор сообщения), <em>MPI_Error</em> (код ошибки); могут быть и
добавочные поля. 

</p><p><em>Идентификатор сообщения (msgtag)</em> - атрибут сообщения, являющийся
целым неотрицательным числом, лежащим в диапазоне от 0 до 32767. <br>
Процессы объединяются в <em>группы</em>, могут быть вложенные группы. Внутри
группы все процессы перенумерованы. С каждой группой ассоциирован свой
<em>коммуникатор</em>. Поэтому при осуществлении пересылки необходимо указать
идентификатор группы, внутри которой производится эта пересылка. Все процессы
содержатся в группе с предопределенным идентификатором <em>MPI_COMM_WORLD</em>.

</p><hr>
<p>При описании процедур MPI будем пользоваться
словом OUT для обозначения "выходных" параметров,
т.е. таких параметров, через которые процедура возвращает
результаты.
</p><hr>
<a name="p2"></a>
<h3>Общие процедуры MPI</h3>

<p><strong>int MPI_Init( int* argc, char*** argv)</strong>

</p><p><em>MPI_Init</em> - инициализация параллельной части приложения. Реальная
инициализация для каждого приложения выполняется не более одного раза,
а если MPI уже был инициализирован, то никакие действия не выполняются
и происходит немедленный возврат из подпрограммы. Все оставшиеся MPI-процедуры
могут быть вызваны только после вызова <em>MPI_Init</em>. 

</p><p>Возвращает: в случае успешного выполнения - <em>MPI_SUCCESS</em>, иначе
- код ошибки. (То же самое возвращают и все остальные функции, рассматриваемые
в данном руководстве.) 
</p><hr>
<p><strong>int MPI_Finalize( void )</strong> 
</p><p><em>MPI_Finalize</em> - завершение параллельной части приложения. Все последующие
обращения к любым MPI-процедурам, в том числе к <em>MPI_Init</em>, запрещены.
К моменту вызова <em>MPI_Finalize</em> некоторым процессом все действия,
требующие его участия в обмене сообщениями, должны быть завершены. <br>
Сложный тип аргументов <em>MPI_Init</em> предусмотрен для того, чтобы передавать
всем процессам аргументы <em>main</em>:</p>

<pre>int main(int argc, char** argv)
{
      MPI_Init(&amp;argc, &amp;argv);
          ...
      MPI_Finalize();
}
</pre>
<hr>
<p><strong>int MPI_Comm_size( MPI_Comm comm, int* size)</strong> 

</p><p>Определение общего числа параллельных процессов в группе <em>comm</em>.
</p><ul>
<li><em>comm</em> - идентификатор группы 
</li><li>OUT <em>size</em> - размер группы 
</li></ul>

<hr>

<p><strong>int MPI_Comm_rank( MPI_Comm comm, int* rank)</strong> 

</p><p>Определение номера процесса в группе <em>comm</em>. Значение, возвращаемое
по адресу <em>&amp;rank</em>, лежит в диапазоне от 0 до <em>size_of_group-1</em>.

</p><ul>
<li><em>comm</em> - идентификатор группы 
</li><li>OUT <em>rank</em> - номер вызывающего процесса в группе <em>comm</em> 
</li></ul>

<hr>

<p><strong>double MPI_Wtime(void)</strong> 
</p><p>Функция возвращает астрономическое время в секундах (вещественное число),
прошедшее с некоторого момента в прошлом. Гарантируется, что этот момент
не будет изменен за время существования процесса. 

</p><hr>
<a name="p3"></a>
<h3>Прием/передача сообщений между отдельными процессами</h3>
<h4>Прием/передача сообщений с блокировкой</h4>


<p><strong>int MPI_Send(void* buf, int count, MPI_Datatype datatype, int dest,
int msgtag, MPI_Comm comm) </strong>

</p><ul>
<li><em>buf</em> - адрес начала буфера посылки сообщения
</li><li><em>count</em> - число передаваемых элементов в сообщении
</li><li><em>datatype</em> - тип передаваемых элементов
</li><li><em>dest</em> - номер процесса-получателя
</li><li><em>msgtag</em> - идентификатор сообщения
</li><li><em>comm</em> - идентификатор группы
</li></ul>

<p>Блокирующая посылка сообщения с идентификатором <em>msgtag</em>, состоящего
из <em>count</em> элементов типа <em>datatype</em>, процессу с номером <em>dest</em>.
Все элементы сообщения расположены подряд в буфере <em>buf</em>. Значение
<em>count</em> может быть нулем. Тип передаваемых элементов <em>datatype</em>
должен указываться с помощью предопределенных констант типа. Разрешается
передавать сообщение самому себе. 
</p><p>Блокировка гарантирует корректность повторного использования всех параметров
после возврата из подпрограммы. Выбор способа осуществления этой гарантии:
копирование в промежуточный буфер или непосредственная передача процессу
<em>dest</em>, остается за MPI. Следует специально отметить, что возврат
из подпрограммы <em>MPI_Send</em> не означает ни того, что сообщение уже
передано процессу <em>dest</em>, ни того, что сообщение покинуло процессорный
элемент, на котором выполняется процесс, выполнивший <em>MPI_Send</em>. 

</p><hr>
<p><strong>int MPI_Recv(void* buf, int count, MPI_Datatype datatype, int source,
int msgtag, MPI_Comm comm, MPI_Status *status)</strong>

</p><ul>
<li>OUT <em>buf</em> - адрес начала буфера приема сообщения 
</li><li><em>count</em> - максимальное число элементов в принимаемом сообщении
</li><li><em>datatype</em> - тип элементов принимаемого сообщения
</li><li><em>source</em> - номер процесса-отправителя
</li><li><em>msgtag</em> - идентификатор принимаемого сообщения
</li><li><em>comm</em> - идентификатор группы
</li><li>OUT <em>status</em> - параметры принятого сообщения
</li></ul>

<p>Прием сообщения с идентификатором <em>msgtag</em> от процесса <em>source</em>
с блокировкой. Число элементов в принимаемом сообщении не должно превосходить
значения <em>count</em>. Если число принятых элементов меньше значения <em>count</em>,
то гарантируется, что в буфере <em>buf</em> изменятся только элементы, соответствующие
элементам принятого сообщения. Если нужно узнать точное число элементов
в сообщении, то можно воспользоваться подпрограммой <em>MPI_Probe</em>. 
</p><p>Блокировка гарантирует, что после возврата из подпрограммы все элементы
сообщения приняты и расположены в буфере <em>buf</em>. 
</p><p>В качестве номера процесса-отправителя можно указать предопределенную константу
<em>MPI_ANY_SOURCE</em> - признак того, что подходит сообщение от любого
процесса. В качестве идентификатора принимаемого сообщения можно указать
константу <em>MPI_ANY_TAG</em> - признак того, что подходит сообщение с любым
идентификатором.
</p><p>Если процесс посылает два сообщения другому процессу и оба эти сообщения
соответствуют одному и тому же вызову <em>MPI_Recv</em>, то первым будет
принято то сообщение, которое было отправлено раньше.
</p><hr>

<p><strong>int MPI_Get_count( MPI_Status *status, MPI_Datatype datatype, int
*count)</strong> 

</p><ul>
<li><em>status</em> - параметры принятого сообщения
</li><li><em>datatype</em> - тип элементов принятого сообщения
</li><li>OUT <em>count</em> - число элементов сообщения
</li></ul>

<p>По значению параметра <em>status</em> данная подпрограмма определяет число
уже принятых (после обращения к <em>MPI_Recv</em>) или принимаемых (после
обращения к <em>MPI_Probe</em> или <em>MPI_Iprobe</em>) элементов сообщения
типа <em>datatype</em>. 
</p><hr>
<p><strong>int MPI_Probe( int source, int msgtag, MPI_Comm comm, MPI_Status
*status)</strong> 

</p><ul>
<li><em>source</em> - номер процесса-отправителя или <em>MPI_ANY_SOURCE</em>
</li><li><em>msgtag</em> - идентификатор ожидаемого сообщения или <em>MPI_ANY_TAG</em>
</li><li><em>comm</em> - идентификатор группы <br>
</li><li>OUT <em>status</em> - параметры обнаруженного сообщения <br>
</li></ul>

<p>Получение информации о структуре ожидаемого сообщения с блокировкой.
Возврата из подпрограммы не произойдет до тех пор, пока сообщение с подходящим
идентификатором и номером процесса-отправителя не будет доступно для получения.
Атрибуты доступного сообщения можно определить обычным образом с помощью
параметра <em>status</em>. Следует обратить внимание, что подпрограмма определяет
только факт прихода сообщения, но реально его не принимает. 
</p><hr>
<h4>Прием/передача сообщений без блокировки</h4>

<p><strong>int MPI_Isend(void *buf, int count, MPI_Datatype datatype, int dest, 
int msgtag, MPI_Comm comm, MPI_Request *request)</strong>

</p><ul>
<li><em>buf</em> - адрес начала буфера посылки сообщения 
</li><li><em>count</em> - число передаваемых элементов в сообщении 
</li><li><em>datatype</em> - тип передаваемых элементов
</li><li><em>dest</em> - номер процесса-получателя 
</li><li><em>msgtag</em> - идентификатор сообщения
</li><li><em>comm</em> - идентификатор группы
</li><li>OUT <em>request</em> - идентификатор асинхронной передачи
</li></ul>

<p>Передача сообщения, аналогичная <em>MPI_Send</em>, однако возврат из подпрограммы
происходит сразу после инициализации процесса передачи без ожидания обработки
всего сообщения, находящегося в буфере <em>buf</em>. Это означает, что нельзя
повторно использовать данный буфер для других целей без получения дополнительной
информации о завершении данной посылки. Окончание процесса передачи (т.е.
того момента, когда можно переиспользовать буфер <em>buf</em> без опасения
испортить передаваемое сообщение) можно определить с помощью параметра
<em>request</em> и процедур <em>MPI_Wait</em> и <em>MPI_Test</em>. <br>
Сообщение, отправленное любой из процедур <em>MPI_Send</em> и <em>MPI_Isend</em>,
может быть принято любой из процедур <em>MPI_Recv</em> и <em>MPI_Irecv</em>.

</p><hr>

<p><strong>int MPI_Irecv(void *buf, int count, MPI_Datatype datatype, int source,
int msgtag, MPI_Comm comm, MPI_Request *request)</strong>

</p><ul>
<li>OUT <em>buf</em> - адрес начала буфера приема сообщения 
</li><li><em>count</em> - максимальное число элементов в принимаемом сообщении 
</li><li><em>datatype</em> - тип элементов принимаемого сообщения 
</li><li><em>source</em> - номер процесса-отправителя
</li><li><em>msgtag</em> - идентификатор принимаемого сообщения 
</li><li><em>comm</em> - идентификатор группы 
</li><li>OUT <em>request</em> - идентификатор асинхронного приема сообщения 
</li></ul>

<p>Прием сообщения, аналогичный <em>MPI_Recv</em>, однако возврат из подпрограммы
происходит сразу после инициализации процесса приема без ожидания получения
сообщения в буфере <em>buf</em>. Окончание процесса приема можно определить
с помощью параметра <em>request</em> и процедур <em>MPI_Wait</em> и <em>MPI_Test</em>.

</p><hr>

<p><strong>int MPI_Wait( MPI_Request *request, MPI_Status *status)</strong>

</p><ul>
<li><em>request</em> - идентификатор асинхронного приема или передачи 
</li><li>OUT <em>status</em> - параметры сообщения 
</li></ul>

<p>Ожидание завершения асинхронных процедур <em>MPI_Isend</em> или <em>MPI_Irecv</em>,
ассоциированных с идентификатором <em>request</em>. В случае приема, атрибуты
и длину полученного сообщения можно определить обычным образом с помощью
параметра <em>status</em>. 
</p><hr>
<p><strong>int MPI_Waitall( int count, MPI_Request *requests, MPI_Status *statuses)
</strong>

</p><ul>
<li><em>count</em> - число идентификаторов 
</li><li><em>requests</em> - массив идентификаторов асинхронного приема или передачи
</li><li>OUT <em>statuses</em> - параметры сообщений
</li></ul>

<p>Выполнение процесса блокируется до тех пор, пока все операции обмена,
ассоциированные с указанными идентификаторами, не будут завершены. Если
во время одной или нескольких операций обмена возникли ошибки, то поле
ошибки в элементах массива <em>statuses</em> будет установлено в соответствующее
значение. 

</p><hr>

<p><strong>int MPI_Waitany( 
int count, MPI_Request *requests, int *index, 
MPI_Status *status) </strong>

</p><ul>
<li><em>count</em> - число идентификаторов 
</li><li><em>requests</em> - массив идентификаторов асинхронного приема или передачи
</li><li>OUT <em>index</em> - номер завершенной операции обмена 
</li><li>OUT <em>status</em> - параметры сообщений 
</li></ul>

<p>Выполнение процесса блокируется до тех пор, пока какая-либо операция
обмена, ассоциированная с указанными идентификаторами, не будет завершена.
Если несколько операций могут быть завершены, то случайным образом выбирается
одна из них. Параметр <em>index</em> содержит номер элемента в массиве <em>requests</em>,
содержащего идентификатор завершенной операции. 

</p><hr>
<p><strong>int MPI_Waitsome( 
int incount, MPI_Request *requests, int *outcount, 
int *indexes, MPI_Status *statuses)</strong>
</p><ul>
<li><em>incount</em> - число идентификаторов 
</li><li><em>requests</em> - массив идентификаторов асинхронного приема или передачи
</li><li>OUT <em>outcount</em> - число идентификаторов завершившихся операций обмена
</li><li>OUT <em>indexes</em> - массив номеров завершившихся операции обмена 
</li><li>OUT <em>statuses</em> - параметры завершившихся сообщений
</li></ul>

<p>Выполнение процесса блокируется до тех пор, пока по крайней мере одна
из операций обмена, ассоциированных с указанными идентификаторами, не будет
завершена. Параметр <em>outcount</em> содержит число завершенных операций,
а первые <em>outcount</em> элементов массива <em>indexes</em> содержат номера
элементов массива <em>requests</em> с их идентификаторами. Первые <em>outcount</em>
элементов массива <em>statuses</em> содержат параметры завершенных операций.

</p><hr>
<p><strong>int MPI_Test( MPI_Request *request, int *flag, MPI_Status *status)
</strong>

</p><ul>
<li><em>request</em> - идентификатор асинхронного приема или передачи
</li><li>OUT <em>flag</em> - признак завершенности операции обмена 
</li><li>OUT <em>status</em> - параметры сообщения
</li></ul>

<p>Проверка завершенности асинхронных процедур <em>MPI_Isend</em> или <em>MPI_Irecv</em>,
ассоциированных с идентификатором <em>request</em>. В параметре <em>flag</em>
возвращает значение 1, если соответствующая операция завершена, и значение
0 в противном случае. Если завершена процедура приема, то атрибуты и длину
полученного сообщения можно определить обычным образом с помощью параметра
<em>status</em>. 

</p><hr>

<p><strong>int MPI_Testall( 
int count, MPI_Request *requests, int *flag, 
MPI_Status *statuses)</strong>

</p><ul>
<li><em>count</em> - число идентификаторов <br>
</li><li><em>requests</em> - массив идентификаторов асинхронного приема или передачи
</li><li>OUT <em>flag</em> - признак завершенности операций обмена <br>
</li><li>OUT <em>statuses</em> - параметры сообщений <br>
</li></ul>

<p>В параметре <em>flag</em> возвращает значение <em>1</em>, если все операции,
ассоциированные с указанными идентификаторами, завершены (с указанием параметров
сообщений в массиве <em>statuses</em>). В противном случае возвращается <em>0</em>,
а элементы массива <em>statuses</em> неопределены. 

</p><hr>

<p><strong>int MPI_Testany(int count, MPI_Request *requests, int *index, 
int *flag, MPI_Status *status)</strong>

</p><ul>
<li><em>count</em> - число идентификаторов 
</li><li><em>requests</em> - массив идентификаторов асинхронного приема или передачи
</li><li>OUT <em>index</em> - номер завершенной операции обмена 
</li><li>OUT <em>flag</em> - признак завершенности операции обмена 
</li><li>OUT <em>status</em> - параметры сообщения 
</li></ul>

<p>Если к моменту вызова подпрограммы хотя бы одна из операций обмена завершилась,
то в параметре <em>flag</em> возвращается значение <em>1</em>, <em>index</em>
содержит номер соответствующего элемента в массиве <em>requests</em>, а <em>status</em>
- параметры сообщения. 
</p><hr>

<p><strong>int MPI_Testsome( 
int incount, MPI_Request *requests, int *outcount, 
int *indexes, MPI_Status *statuses)</strong>

</p><ul>
<li><em>incount</em> - число идентификаторов 
</li><li><em>requests</em> - массив идентификаторов асинхронного приема или передачи
</li><li>OUT <em>outcount</em> - число идентификаторов завершившихся операций обмена
</li><li>OUT <em>indexes</em> - массив номеров завершившихся операции обмена
</li><li>OUT <em>statuses</em> - параметры завершившихся операций <br>
</li></ul>

<p>Данная подпрограмма работает так же, как и <em>MPI_Waitsome</em>, 
за исключением того, что возврат происходит немедленно. Если ни одна из указанных операций
не завершилась, то значение <em>outcount</em> будет равно нулю. 
</p><hr>

<p><strong>int MPI_Iprobe( 
int source, int msgtag, MPI_Comm comm, int *flag, 
MPI_Status *status)</strong>

</p><ul>
<li><em>source</em> - номер процесса-отправителя или <em>MPI_ANY_SOURCE</em>
</li><li><em>msgtag</em> - идентификатор ожидаемого сообщения или <em>MPI_ANY_TAG</em>
</li><li><em>comm</em> - идентификатор группы
</li><li>OUT <em>flag</em> - признак завершенности операции обмена 
</li><li>OUT <em>status</em> - параметры обнаруженного сообщения 
</li></ul>

<p>Получение информации о поступлении и структуре ожидаемого сообщения
без блокировки. В параметре <em>flag</em> возвращает значение <em>1</em>, если
сообщение с подходящими атрибутами уже может быть принято (в этом случае
ее действие полностью аналогично <em>MPI_Probe</em>), и значение <em>0</em>,
если сообщения с указанными атрибутами еще нет. 

</p><hr>
<a name="p4"></a>
<h3>Объединение запросов на взаимодействие</h3>

<p>Процедуры данной группы позволяют снизить накладные расходы, возникающие
в рамках одного процессора при обработке приема/передачи и перемещении
необходимой информации между процессом и сетевым контроллером. Несколько
запросов на прием и/или передачу могут объединяться вместе для того, чтобы
далее их можно было бы запустить одной командой. Способ приема сообщения
никак не зависит от способа его посылки: сообщение, отправленное с помощью
объединения запросов либо обычным способом, может быть принято как обычным
способом, так и с помощью объединения запросов. 


</p><p><strong>int MPI_Send_init( 
void *buf, int count, MPI_Datatype datatype, int dest, 
int msgtag, MPI_Comm comm, MPI_Request *request)</strong>

</p><ul>
<li><em>buf</em> - адрес начала буфера посылки сообщения
</li><li><em>count</em> - число передаваемых элементов в сообщении
</li><li><em>datatype</em> - тип передаваемых элементов
</li><li><em>dest</em> - номер процесса-получателя
</li><li><em>msgtag</em> - идентификатор сообщения 
</li><li><em>comm</em> - идентификатор группы
</li><li>OUT <em>request</em> - идентификатор асинхронной передачи 
</li></ul>

<p>Формирование запроса на выполнение пересылки данных. Все параметры точно
такие же, как и у подпрограммы <em>MPI_Isend</em>, однако в отличие от нее
пересылка не начинается до вызова подпрограммы <em>MPI_Startall</em>. 

</p><hr>
<p><strong>int MPI_Recv_init( 
void *buf, int count, MPI_Datatype datatype, int source, 
int msgtag, MPI_Comm comm, MPI_Request *request)</strong>

</p><ul>
<li>OUT <em>buf</em> - адрес начала буфера приема сообщения
</li><li><em>count</em> - число принимаемых элементов в сообщении 
</li><li><em>datatype</em> - тип принимаемых элементов
</li><li><em>source</em> - номер процесса-отправителя
</li><li><em>msgtag</em> - идентификатор сообщения
</li><li><em>comm</em> - идентификатор группы
</li><li>OUT <em>request</em> - идентификатор асинхронного приема 
</li></ul>

<p>Формирование запроса на выполнение приема данных. Все параметры точно
такие же, как и у подпрограммы <em>MPI_Irecv</em>, однако в отличие от
нее реальный прием не начинается до вызова подпрограммы <em>MPI_Startall</em>.

</p><hr>
<p><strong>MPI_Startall( int count, MPI_Request *requests) </strong>

</p><ul>
<li><em>count</em> - число запросов на взаимодействие 
</li><li>OUT <em>requests</em> - массив идентификаторов приема/передачи 
</li></ul>

<p>Запуск всех отложенных взаимодействий, ассоциированных вызовами подпрограмм
<em>MPI_Send_init</em> и <em>MPI_Recv_init</em> с элементами массива запросов
<em>requests</em>. Все взаимодействия запускаются в режиме без блокировки,
а их завершение можно определить обычным образом с помощью процедур <em>MPI_Wait</em>
и <em>MPI_Test</em>. 
</p><hr>
<a name="p5"></a>
<h3>Совмещенные прием/передача сообщений</h3>

<p><strong>int MPI_Sendrecv( 
void *sbuf, int scount, MPI_Datatype stype, 
int dest, int stag, void *rbuf, int rcount, 
MPI_Datatype rtype, int source, MPI_Datatype rtag, 
MPI_Comm comm, MPI_Status *status)</strong>

</p><ul>
<li><em>sbuf</em> - адрес начала буфера посылки сообщения
</li><li><em>scount</em> - число передаваемых элементов в сообщении 
</li><li><em>stype</em> - тип передаваемых элементов
</li><li><em>dest</em> - номер процесса-получателя
</li><li><em>stag</em> - идентификатор посылаемого сообщения 
</li><li>OUT <em>rbuf</em> - адрес начала буфера приема сообщения
</li><li><em>rcount</em> - число принимаемых элементов сообщения 
</li><li><em>rtype</em> - тип принимаемых элементов
</li><li><em>source</em> - номер процесса-отправителя
</li><li><em>rtag</em> - идентификатор принимаемого сообщения
</li><li><em>comm</em> - идентификатор группы 
</li><li>OUT <em>status</em> - параметры принятого сообщения 
</li></ul>

<p>Данная операция объединяет в едином запросе посылку и прием сообщений.
Принимающий и отправляющий процессы могут являться одним и тем же процессом.
Сообщение, отправленное операцией <em>MPI_Sendrecv</em>, может быть принято
обычным образом, и точно также операция <em>MPI_Sendrecv</em> может принять
сообщение, отправленное обычной операцией <em>MPI_Send</em>. Буфера приема
и посылки обязательно должны быть различными. 

</p><hr>
<a name="p6"></a>
<h3>Коллективные взаимодействия процессов</h3>

<p>В операциях коллективного взаимодействия процессов участвуют все процессы
коммуникатора. Соответствующая процедура должна быть вызвана каждым процессом,
быть может, со своим набором параметров. Возврат из процедуры коллективного
взаимодействия может произойти в тот момент, когда участие процесса в данной
операции уже закончено. Как и для блокирующих процедур, возврат означает
то, что разрешен свободный доступ к буферу приема или посылки, но не означает
ни того, что операция завершена другими процессами, ни даже того, что она
ими начата (если это возможно по смыслу операции). 

</p><p><strong>int MPI_Bcast(void *buf, int count, MPI_Datatype datatype,
int source, MPI_Comm comm)</strong> 
</p><ul>
<li>OUT <em>buf</em> - адрес начала буфера посылки сообщения
</li><li><em>count</em> - число передаваемых элементов в сообщении 
</li><li><em>datatype</em> - тип передаваемых элементов
</li><li><em>source</em> - номер рассылающего процесса 
</li><li><em>comm</em> - идентификатор группы 
</li></ul>

<p>Рассылка сообщения от процесса <em>source</em> всем процессам, включая
рассылающий процесс. При возврате из процедуры содержимое буфера <em>buf</em>
процесса <em>source</em> будет скопировано в локальный буфер процесса. Значения
параметров <em>count</em>, <em>datatype</em> и <em>source</em> должны быть одинаковыми
у всех процессов. 

</p><hr>
<p><strong>int MPI_Gather( 
void *sbuf, int scount, MPI_Datatype stype, 
void *rbuf, int rcount, MPI_Datatype rtype, 
int dest, MPI_Comm comm)</strong>

</p><ul>
<li><em>sbuf</em> - адрес начала буфера посылки 
</li><li><em>scount</em> - число элементов в посылаемом сообщении 
</li><li><em>stype</em> - тип элементов отсылаемого сообщения
</li><li>OUT <em>rbuf</em> - адрес начала буфера сборки данных 
</li><li><em>rcount</em> - число элементов в принимаемом сообщении 
</li><li><em>rtype</em> - тип элементов принимаемого сообщения
</li><li><em>dest</em> - номер процесса, на котором происходит сборка данных
</li><li><em>comm</em> - идентификатор группы 
</li><li>OUT <em>ierror</em> - код ошибки 

</li></ul>

<p>Сборка данных со всех процессов в буфере <em>rbuf</em> процесса <em>dest</em>.
Каждый процесс, включая <em>dest</em>, посылает содержимое своего буфера
<em>sbuf</em> процессу <em>dest</em>. Собирающий процесс сохраняет данные в
буфере <em>rbuf</em>, располагая их в порядке возрастания номеров процессов.
Параметр <em>rbuf</em> имеет значение только на собирающем процессе и на
остальных игнорируется, значения параметров <em>count</em>, <em>datatype</em>
и <em>dest</em> должны быть одинаковыми у всех процессов. 

</p><hr>

<p><strong>int MPI_Allreduce( 
void *sbuf, void *rbuf, int count, 
MPI_Datatype datatype, MPI_Op op, MPI_Comm comm) 
</strong>
</p><ul>
<li><em>sbuf</em> - адрес начала буфера для аргументов 
</li><li>OUT <em>rbuf</em> - адрес начала буфера для результата 
</li><li><em>count</em> - число аргументов у каждого процесса 
</li><li><em>datatype</em> - тип аргументов 
</li><li><em>op</em> - идентификатор глобальной операции 
</li><li><em>comm</em> - идентификатор группы 
</li></ul>

<p>Выполнение <em>count</em> глобальных операций <em>op</em> с возвратом <em>count</em>
результатов во всех процессах в буфере <em>rbuf</em>. Операция выполняется
независимо над соответствующими аргументами всех процессов. Значения параметров
<em>count</em> и <em>datatype</em> у всех процессов должны быть одинаковыми.
Из соображений эффективности реализации предполагается, что операция <em>op</em>
обладает свойствами ассоциативности и коммутативности. 
</p><hr>

<p><strong>int MPI_Reduce( 
void *sbuf, void *rbuf, int count, 
MPI_Datatype datatype, MPI_Op op, int root, MPI_Comm comm) 
</strong>

</p><ul>
<li><em>sbuf</em> - адрес начала буфера для аргументов 
</li><li>OUT <em>rbuf</em> - адрес начала буфера для результата
</li><li><em>count</em> - число аргументов у каждого процесса 
</li><li><em>datatype</em> - тип аргументов 
</li><li><em>op</em> - идентификатор глобальной операции 
</li><li><em>root</em> - процесс-получатель результата 
</li><li><em>comm</em> - идентификатор группы 
</li></ul>

<p>Функция аналогична предыдущей, но результат будет записан в буфер <em>rbuf</em>
только у процесса <em>root</em>. 

</p><hr>
<a name="p7"></a>
<h3>Синхронизация процессов</h3>

<p><strong>int MPI_Barrier( MPI_Comm comm) </strong>

</p><ul>
<li><em>comm</em> - идентификатор группы 
</li></ul>

<p>Блокирует работу процессов, вызвавших данную процедуру, до тех пор,
пока все оставшиеся процессы группы <em>comm</em> также не выполнят эту процедуру.
</p><hr>
<a name="p8"></a>
<h3>Работа с группами процессов</h3>

<p><strong>int MPI_Comm_split( MPI_Comm comm,
int color, int key, MPI_Comm *newcomm)
</strong>

</p><ul>
<li><em>comm</em> - идентификатор группы 
</li><li><em>color</em> - признак разделения на группы 
</li><li><em>key</em> - параметр, определяющий нумерацию в новых группах 
</li><li>OUT <em>newcomm</em> - идентификатор новой группы 
</li></ul>
 
<p>Данная процедура разбивает все множество процессов, входящих в группу
<em>comm</em>, на непересекающиеся подгруппы - одну подгруппу на каждое значение
параметра <em>color</em> (неотрицательное число). Каждая новая подгруппа
содержит все процессы одного цвета. Если в качестве <em>color</em> указано
значение <em>MPI_UNDEFINED</em>, то в <em>newcomm</em> будет возвращено значение
<em>MPI_COMM_NULL</em>. 

</p><hr>
<p><strong>int MPI_Comm_free( MPI_Comm comm) </strong>

</p><ul>
<li>OUT <em>comm</em> - идентификатор группы 

</li></ul>

<p>Уничтожает группу, ассоциированную с идентификатором <em>comm</em>, который
после возвращения устанавливается в <em>MPI_COMM_NULL</em>. 

</p><hr>
<a name="p9"></a>
<h3>Предопределенные константы</h3>

<h4>Предопределенные константы типа элементов сообщений</h4>

<center><table border="1">
<tbody><tr>
<td>

</td></tr><tr bgcolor="#cbd1da">
<td>Константы MPI 
</td><td>Тип в C 
</td></tr><tr>
<td>


</td></tr><tr>
<td><em>MPI_CHAR </em>
</td><td>signed char 

</td></tr><tr>
<td><em>MPI_SHORT </em>
</td><td>signed int 

</td></tr><tr>
<td><em>MPI_INT </em>
</td><td>signed int 

</td></tr><tr>
<td><em>MPI_LONG </em>
</td><td>signed long int 

</td></tr><tr>
<td><em>MPI_UNSIGNED_CHAR </em>
</td><td>unsigned char 

</td></tr><tr>
<td><em>MPI_UNSIGNED_SHORT </em>
</td><td>unsigned int 

</td></tr><tr>
<td><em>MPI_UNSIGNED </em>
</td><td>unsigned int 

</td></tr><tr>
<td><em>MPI_UNSIGNED_LONG </em>
</td><td>unsigned long int 

</td></tr><tr>
<td><em>MPI_FLOAT </em>
</td><td>float 

</td></tr><tr>
<td><em>MPI_DOUBLE </em>
</td><td>double 

</td></tr><tr>
<td><em>MPI_LONG_DOUBLE </em>
</td><td>long double 

</td></tr></tbody></table></center>

<hr>
<p><strong>Другие предопределенные типы </strong>

</p><p><em>MPI_Status</em> - структура; атрибуты сообщений; содержит три обязательных
поля: 
</p><ul>
<li><em>MPI_Source</em> (номер процесса отправителя) 
</li><li><em>MPI_Tag</em> (идентификатор сообщения) 
</li><li><em>MPI_Error</em> (код ошибки) 
</li></ul>
<hr>
<p><em>MPI_Request</em> - системный тип; идентификатор операции посылки-приема
сообщения 
</p><hr>
<p><em>MPI_Comm</em> - системный тип; идентификатор группы (коммуникатора)
</p><ul>
<li><p><em>MPI_COMM_WORLD</em>  - зарезервированный идентификатор группы, состоящей их всех процессов
приложения
</p></li></ul>
<hr>
<p><strong>Константы-пустышки</strong>
</p><ul>
<li><em>MPI_COMM_NULL</em> 
</li><li><em>MPI_DATATYPE_NULL</em> 
</li><li><em>MPI_REQUEST_NULL</em> 
</li></ul>
<p><b>Константа неопределенного значения</b> 
</p><ul>
<li><em>MPI_UNDEFINED</em> 
</li></ul>
<hr>
<p><strong>Глобальные операции</strong> 
</p><p><em>MPI_MAX</em> 
</p><p><em>MPI_MIN</em> 
</p><p><em>MPI_SUM</em> 
</p><p><em>MPI_PROD</em> 
</p><hr>
<p><strong>Любой процесс/идентификатор</strong> 
</p><p><em>MPI_ANY_SOURCE</em> 
</p><p><em>MPI_ANY_TAG</em> 
</p><hr>
<p><strong>Код успешного завершения процедуры</strong> 
</p><p><em>MPI_SUCCESS</em> 
</p><hr>

<table align="center" bgcolor="#f0ffff" border="1" cellspacing="5" width="90%">
<tbody><tr>
<td align="center" bgcolor="#ffffff">
<img src="mpi_files/cross.gif" align="top">
<a href="http://parallel.ru/vvv/examples.html">Примеры MPI-программ</a>

</td><td align="center" bgcolor="#ffffff">
<img src="mpi_files/cross.gif" align="top">
<a href="http://parallel.ru/parallel/tech/tech_dev/mpi.html">Страница MPI</a>

</td><td align="center" bgcolor="#ffffff">
<img src="mpi_files/cross.gif" align="top">
<a href="http://parallel.ru/vvv/index.html">
Содержание курса</a>

</td><td align="center" bgcolor="#ffffff">
<img src="mpi_files/cross.gif" align="top">
<a href="http://parallel.ru/vvv/lec6.html">Следующая лекция. Технология программирования OpenMP.</a>
</td></tr>
</tbody></table>

<hr>
<p class="copyright" align="right"> © Лаборатория Параллельных Информационных Технологий, НИВЦ МГУ
<!--- BEGIN code for counters ---><img src="mpi_files/top100.gif" alt="Rambler's Top100" border="0" height="1" width="1"><!--- END code for counters --->
</p></body></html>